1. Before ingesting data into a pre-existing reporting structure, I would have a number of logistical and conceptual questions I would want to ask and discuss with my team.

   1. First, before doing any technical work, I would want to ensure that we have permission to use the new data. I would ask if the owner of the new data is aware that we are using it. Is this data open source? Are we being given this data by an outside stakeholder? Should we be taking extra security precautions when handling this data?
   2. Relatedly, I would be concerned with whether or not the new data is reliable and accurate. I would ask, how was this data collected in the first place? What was it's original use? Do we trust where this data is coming from?
   3. Next, it's important to check that the new data actually represents what we think it represents. For example, let's say the new data source contains data pertaining to voter turnout for a given election. If the data has a column named 'percent_turnout', we need to clarify what this actually means. Is this the percent of eligible voters who voted? Is this the percent of registered voters who voted? Is this percent in terms of fips, zip code, county, state, etc?
   4. As a data engineer, one major concern would be if the new data matches the pre-existing report structure. For example, does the new data have all of the pre-existing columns, or are certain columns missing? What transformations are needed so that the data types and formats of the new and pre-existing data align?
   5. In order to make our jobs easier moving forward, I would want to know if we are able to injest this new data in an automated fashion. Can we access it via API? Do we need to download the new data manually? Will the data be available in 1 week, month, or year+?
   6. Finally, I would want to know if there is a way we can check ourselves before injesting new data into our database (for example, in a staging database). That way, we can write automated tests to ensure that our production database is always in good shape.

2. When presenting a proposal to my team to make changes to data processing or pipelines, I would first take time on my own to form an idea or set of questions. Once I felt like I had a thoughful idea, I would present it to my team during the approriate team meeting, and I would come prepared with reasons why the change would be worthwhile. I would be sure to have examples ready of how this change could make our work better. In preparation for this type of conversation, I could even test out a small example of the change with a subset of data (not in production) and show that the change could work.\
   \
   When working on a team, it's crucial to have open and respsectful discussions with all parties involved. I would want to make sure that everyone's voices and concerns are heard. I would hope that on any engineering team, everyone is encouraged to work together and consider each other's proposals as valid and worth discusion. I would not make any changes to a process or pipeline until everyone on the team is on board. If a given member is still not on board, I would want to have further discussions of why and think of ways to address their concerns.

3. There are a number of ways that I know whether or not I have 'good data'. They fall into the following categories:
   1. Spot / self checking. When I worked as a Python Engineer for Civic Eagle, my job was the acquire data from public state websites using web scraping. Qhile writing a given web scraper, I would use a python shell to print out and check my data. I made sure that the data I thought I was grabbing was the data I was actually grabbing. I also made sure I did not need to use any regex or string manipulation to transform my data. Using a python shell, print statements, and debuggers is a very useful way to check myself as I code.
   2. Automated testing and validation. Although spot checking is great for development, we need a more robust set of tests to ensure that out data pipeline works from start to finish. This is where automated testing and validion comes in. I would set up end-to-end tests to ensure that at every point in our pipeline, we are sending output (and receiving input) as expected. Such testing should be set on some sort of schedule so that we know our data is 'good' at all times.
   3. Gut feeling. Having worked with different types of data over the past few years, sometimes I just know that what I'm working with is accurate, robust, and reliable (or not). If the data source is not reliable, or there is a lack of documentation, or there are typos and errors within the data, it's probably not a good idea to use it.
